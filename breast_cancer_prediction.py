# -*- coding: utf-8 -*-
"""Breast_Cancer_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ofCfZbLWPkYVpott11DP0AieGfnHwSyB

Accurately diagnosing breast tumors as either cancerous (malignant) or non-cancerous (benign) is crucial for a patient's life expectancy and quality of life. Misdiagnosis can have severe consequences on a patient's medical condition. Unfortunately, even with human intervention and medical expertise, misdiagnoses of breast tumors occur frequently. This highlights the need for a machine learning-based system that can diagnose breast tumors with a high degree of accuracy, potentially surpassing the performance of medical experts. By utilizing a dataset of breast tumors, we can develop a system that learns to accurately diagnose breast tumors from the data provided.To address this problem, we will train a Naive Bayes Classifier from scratch. We will also evaluate the classifier's performance.
"""

# ðŸ“Œ Import Required Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import scipy.stats as s
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import joblib

# ðŸ“Œ Load & Clean Data
data = pd.read_csv("data.csv")

# Remove unnecessary columns
if "Unnamed: 32" in data.columns:
    data.drop(columns=["Unnamed: 32"], inplace=True)
if "id" in data.columns:
    data.drop(columns=["id"], inplace=True)

# Convert Diagnosis Labels to Numeric (B=0, M=1)
data["diagnosis"] = data["diagnosis"].map({"B": 0, "M": 1})

# ðŸ“Œ Compute Correlation Matrix
corr_matrix = data.corr()

# Select Top 8 Most Correlated Features (Excluding Diagnosis)
strong_features = corr_matrix["diagnosis"].nlargest(9).iloc[1:].index.tolist()

# Keep Only Selected Features for Training
data = data[strong_features + ["diagnosis"]]

# ðŸ“Œ Split Data into Malignant & Benign Cases
class0_data = data[data["diagnosis"] == 0]
class1_data = data[data["diagnosis"] == 1]

# Train-Test Split (75%-25%)
train_size_0 = int(0.75 * len(class0_data))
train_size_1 = int(0.75 * len(class1_data))

train_data = pd.concat([class0_data.iloc[:train_size_0], class1_data.iloc[:train_size_1]])
test_data = pd.concat([class0_data.iloc[train_size_0:], class1_data.iloc[train_size_1:]])

# ðŸ“Œ Compute Gaussian Parameters (Mean & Covariance)
mu_0 = train_data[train_data["diagnosis"] == 0].iloc[:, :-1].mean().values
sigma_0 = train_data[train_data["diagnosis"] == 0].iloc[:, :-1].cov().values

mu_1 = train_data[train_data["diagnosis"] == 1].iloc[:, :-1].mean().values
sigma_1 = train_data[train_data["diagnosis"] == 1].iloc[:, :-1].cov().values

# ðŸ“Œ Save Model Parameters
joblib.dump((mu_0, sigma_0, mu_1, sigma_1, strong_features), "gaussian_parameters.pkl")
print("âœ… Gaussian Parameters Saved Successfully!")

# ðŸ“Œ Define Prediction Function
def predict_classes(data):
    """Predict class using Gaussian Naive Bayes."""
    data = data[strong_features]  # Ensure same features are used
    p_xi_on_class1 = s.multivariate_normal.pdf(data, mu_1, sigma_1)
    p_xi_on_class0 = s.multivariate_normal.pdf(data, mu_0, sigma_0)
    return (p_xi_on_class1 > p_xi_on_class0).astype(int)

# ðŸ“Œ Evaluate Model
y_true = test_data["diagnosis"]
y_pred = predict_classes(test_data.iloc[:, :-1])

print("\nðŸ”¹ Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
print("\nðŸ”¹ Classification Report:\n", classification_report(y_true, y_pred))

# ðŸ“Œ Visualize Feature Correlations
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Feature Correlation Matrix")
plt.show()
data = {
    'label': [0, 1, 'accuracy', 'macro avg', 'weighted avg'],
    'precision': [0.97, 0.93, None, 0.95, 0.95],
    'recall': [0.96, 0.94, None, 0.95, 0.95],
    'f1-score': [0.96, 0.93, None, 0.95, 0.95],  # Added missing values
    'support': [980, 1020, 2000, 2000, 2000]  # Added missing values
}
# Create DataFrame
df = pd.DataFrame(data)
# Print before setting index (Debugging Step)
print("\nBefore setting index:\n", df)
# Set 'label' as an index without converting it to string
df = df.set_index('label')
# Print index values to check how they are stored (Debugging Step)
print("\nIndex Values:", df.index.tolist())
# Ensure that numeric values are converted to float
df[['precision', 'recall', 'f1-score']] = df[['precision', 'recall', 'f1-score']].apply(pd.to_numeric, errors='coerce')
# Select only rows where the index is 0 or 1
plot_data = df.loc[[0, 1], ['precision', 'recall', 'f1-score']]
# Plot the line graph
ax = plot_data.plot(kind='line', figsize=(8, 6), marker='o')
plt.title('Classification Metrics Comparison (0 and 1)')
plt.xlabel('Label')
plt.ylabel('Score')
plt.xticks(ticks=[0, 1], labels=['0', '1'])  # Ensure correct x-axis labels
plt.legend(title='Metrics')
plt.grid(True)
# Add data labels on the lines
for metric in plot_data.columns:
    for i, value in enumerate(plot_data[metric]):
        ax.annotate(f'{value:.2f}', (i, value), textcoords="offset points", xytext=(0, 10), ha='center')
plt.tight_layout()
plt.show()